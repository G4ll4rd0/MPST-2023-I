{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f6dcbc7",
   "metadata": {},
   "source": [
    "___\n",
    "<img style=\"float: right; margin: 0px 0px 15px 15px;\" src=\"https://editor.analyticsvidhya.com/uploads/56846f3ff4855a71201b102f92a733fd5a875.png\" width=\"500px\" height=\"100px\" />\n",
    "\n",
    "\n",
    "# <font color= #8A0829> Preparar datos de series de tiempo para el uso de redes neuronales.</font>\n",
    "\n",
    "<Strong> Objetivos </Strong>\n",
    "- Comprender cómo transformar datos de series de tiempo en un problema de machine learning supervisado.\n",
    "- Aprender a tranformar datos en tensores que puedan ser usados luego para un entrenamiento de series de tiempo.\n",
    "> Referencias: \n",
    "    > - Capítulo 6 de [Deep Learning for Time Series Forecasting: Predict the Future with MLPs, CNNs and LSTMs in Python](https://machinelearningmastery.com/deep-learning-for-time-series-forecasting/)\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8230698c",
   "metadata": {},
   "source": [
    "# Cómo transformar las series temporales en un problema de aprendizaje supervisado\n",
    "\n",
    "La previsión de series temporales puede plantearse como un problema de aprendizaje supervisado. Este nuevo marco para sus datos de series temporales le permite acceder al conjunto de algoritmos estándar de aprendizaje automático lineal y no lineal para su problema. En esta lección, descubrirá cómo puede replantear su problema de series temporales como un problema de aprendizaje supervisado para el aprendizaje automático.\n",
    "\n",
    "## 1. Aprendizaje automático supervisado\n",
    "\n",
    "La mayor parte del aprendizaje automático práctico utiliza el aprendizaje supervisado. El aprendizaje supervisado es aquel en el que se tienen variables de entrada (X) y una variable de salida (y) y se utiliza un algoritmo para aprender la función de asignación de la entrada a la salida.\n",
    "$$\n",
    "Y = f(X)\n",
    "$$\n",
    "El objetivo es aproximarse a la función subyacente real tan bien que, cuando se tengan nuevos datos de entrada (X), se puedan predecir las variables de salida (y) para esos datos.\n",
    "\n",
    "Se denomina aprendizaje supervisado porque el proceso de aprendizaje de un algoritmo a partir del conjunto de datos de entrenamiento puede considerarse como un profesor que supervisa el proceso de aprendizaje. Conocemos las respuestas correctas; el algoritmo realiza predicciones de forma iterativa a partir de los datos de entrenamiento y se corrige realizando actualizaciones. El aprendizaje se detiene cuando el algoritmo alcanza un nivel de rendimiento aceptable. Los problemas de aprendizaje supervisado pueden agruparse a su vez en problemas de regresión y clasificación.\n",
    "\n",
    "- **Clasificación**: Un problema de clasificación es cuando la variable de salida es una categoría, como rojo y azul o enfermedad y no enfermedad.\n",
    "- **Regresión**: Un problema de regresión es cuando la variable de salida es un valor real, como dólares o peso.\n",
    "\n",
    "## 2. Ventana móvil\n",
    "\n",
    "Los datos de **series temporales pueden plantearse como un aprendizaje supervisado**. Dada una secuencia de números para un conjunto de datos de series temporales, podemos reestructurar los datos para que parezcan un problema de aprendizaje supervisado. Para ello, podemos utilizar **los pasos temporales anteriores como variables de entrada** y utilizar el siguiente paso temporal como variable de salida. Concretemos esto con un ejemplo. Imaginemos que tenemos una serie temporal como la siguiente:\n",
    "\n",
    "| time, | measure |\n",
    "|:-----:|:-------:|\n",
    "|   1,  | 100     |\n",
    "|   2,  | 110     |\n",
    "|   3,  | 108     |\n",
    "|   4,  | 115     |\n",
    "|   5,  | 120     |\n",
    "\n",
    "Podemos reestructurar este conjunto de datos de series temporales como un problema de aprendizaje supervisado utilizando el valor del paso temporal anterior para predecir el valor del paso temporal siguiente. Reorganizando el conjunto de datos de series temporales de esta forma, los datos tendrían el siguiente aspecto:\n",
    "\n",
    "|  X,  |  y  |\n",
    "|:----:|:---:|\n",
    "|  ?,  | 100 |\n",
    "| 100, | 110 |\n",
    "| 110, | 108 |\n",
    "| 108, | 115 |\n",
    "| 115, | 120 |\n",
    "| 120, | ?   |\n",
    "\n",
    "El uso de pasos temporales anteriores para predecir el paso temporal siguiente se denomina método de la ventana deslizante.\n",
    "El número de pasos temporales anteriores se denomina anchura de la ventana o tamaño del desfase.\n",
    "\n",
    "A partir de este sencillo ejemplo, podemos observar algunas cosas:\n",
    "1. Podemos ver cómo esto puede funcionar para **convertir una serie temporal en un problema de aprendizaje supervisado de regresión o clasificación** para valores reales o valores etiquetados de series temporales.\n",
    "2. El conjunto de datos se prepara de forma que pueda aplicarse cualquiera de los algoritmos de aprendizaje automático lineales y no lineales estándar, siempre que se mantenga el orden de las filas.\n",
    "3. Podemos ver cómo la anchura de la ventana deslizante puede aumentarse para incluir más pasos temporales anteriores.\n",
    "4. Podemos ver cómo el enfoque de la ventana deslizante puede utilizarse en una serie temporal que tiene más de un valor, o las llamadas **series temporales multivariantes**.\n",
    "\n",
    "## 3. Ventana móvil con múltiples variables\n",
    "\n",
    "Se trata de conjuntos de datos en los que se observan dos o más variables en cada momento.\n",
    "\n",
    "El mejor momento para utilizar el aprendizaje automático en las series temporales es aquel en el que los métodos clásicos fallan. Esto puede ocurrir con series temporales univariantes complejas, y es más probable con series temporales multivariantes dada la complejidad adicional. A continuación se presenta otro ejemplo práctico para concretar el método de la ventana móvil para series temporales multivariantes. Supongamos que tenemos el siguiente conjunto de datos de series temporales multivariantes con dos observaciones en cada paso temporal. Supongamos también que sólo nos **interesa predecir la measure2**.\n",
    "\n",
    "| time, | measure1, | measure2 |\n",
    "|:-----:|-----------|----------|\n",
    "|   1,  | 0.2,      | 88       |\n",
    "|   2,  | 0.5,      | 89       |\n",
    "|   3,  | 0.7,      | 87       |\n",
    "|   4,  | 0.4,      | 88       |\n",
    "|   5,  | 1.0,      | 90       |\n",
    "\n",
    "Podemos replantear este conjunto de datos de series temporales como un problema de **aprendizaje supervisado** con un ancho de ventana de uno. Esto significa que utilizaremos los valores de los pasos temporales anteriores de la measure1 y la measure2. También dispondremos del valor del siguiente paso temporal de la medida1. A continuación, predeciremos el valor del siguiente paso temporal de la measure2. Esto nos dará 3 características de entrada y un valor de salida a predecir para cada patrón de entrenamiento.\n",
    "\n",
    "|  X1, | X2, | X3,  | y  |\n",
    "|:----:|-----|------|----|\n",
    "|  ?,  | ?,  | 0.2, | 88 |\n",
    "| 0.2, | 88, | 0.5, | 89 |\n",
    "| 0.5, | 89, | 0.7, | 87 |\n",
    "| 0.7, | 87, | 0.4, | 88 |\n",
    "| 0.4, | 88, | 1.0, | 90 |\n",
    "| 1.0, | 90, | ?,   | ?  |\n",
    "\n",
    "Este ejemplo plantea la pregunta ¿Qué pasaría si quisiéramos predecir tanto la measure1 como la measure2 para el siguiente paso temporal con una ventana móvil de uno?\n",
    "\n",
    "|  X1, | X2, | y1,  | y2 |\n",
    "|:----:|-----|------|----|\n",
    "|  ?,  | ?,  | 0.2, | 88 |\n",
    "| 0.2, | 88, | 0.5, | 89 |\n",
    "| 0.5, | 89, | 0.7, | 87 |\n",
    "| 0.7, | 87, | 0.4, | 88 |\n",
    "| 0.4, | 88, | 1.0, | 90 |\n",
    "| 1.0, | 90, | ?,   | ?  |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1222f1",
   "metadata": {},
   "source": [
    "## 4. Ventana Móvil con Varios Pasos\n",
    "\n",
    "El número de pasos temporales que hay que prever es importante. Una vez más, es tradicional utilizar distintos nombres para el problema en función del número de pasos temporales que haya que pronosticar:  \n",
    "- **Previsión de un paso**: Se trata de predecir el siguiente paso temporal (t+1).\n",
    "- **Previsión en varios pasos**: Se trata de predecir dos o más pasos temporales futuros.\n",
    "\n",
    "Considere el mismo ejemplo discutido anteriormente\n",
    "\n",
    "| time, | measure |\n",
    "|:-----:|:-------:|\n",
    "|   1,  | 100     |\n",
    "|   2,  | 110     |\n",
    "|   3,  | 108     |\n",
    "|   4,  | 115     |\n",
    "|   5,  | 120     |\n",
    "\n",
    "Podemos enmarcar esta serie temporal como un conjunto de datos de previsión en dos etapas para el aprendizaje supervisado con un ancho de ventana de uno, como sigue:\n",
    "\n",
    "|  X1, | y1,  | y2  |\n",
    "|:----:|------|-----|\n",
    "|   ?  | 100, | 110 |\n",
    "| 100, | 110, | 108 |\n",
    "| 110, | 108, | 115 |\n",
    "| 108, | 115, | 120 |\n",
    "| 115, | 120, | ?   |\n",
    "| 120, | ?,   | ?   |\n",
    "\n",
    "Podemos ver que la primera fila y las dos últimas no pueden utilizarse para entrenar un modelo supervisado. También es un buen ejemplo para mostrar la sobrecarga de las variables de entrada. Específicamente, que un modelo supervisado sólo tiene X1 con el que trabajar para predecir tanto y1 como y2. **Se necesita una cuidadosa reflexión y experimentación en su problema para encontrar un ancho de ventana que resulte en un rendimiento aceptable del modelo.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2018ed",
   "metadata": {},
   "source": [
    "# Cómo preparar datos de series temporales para CNN y LSTM\n",
    "\n",
    "Los datos de series temporales deben transformarse antes de poder utilizarse para ajustar un modelo de aprendizaje supervisado. En esta forma, los datos pueden utilizarse inmediatamente para ajustar un algoritmo de aprendizaje automático supervisado e incluso una red neuronal Perceptrón Multicapa. Para que los datos puedan ajustarse a una red neuronal convolucional (CNN) o a una red neuronal de memoria a corto plazo (LSTM), es necesaria otra transformación. En concreto, la estructura bidimensional de los datos de aprendizaje supervisado debe transformarse en una estructura tridimensional.\n",
    "\n",
    "## 1. Series temporales a supervisadas\n",
    "\n",
    "Los datos de series temporales requieren una preparación antes de poder utilizarlos para entrenar un modelo de aprendizaje supervisado, como una red neuronal LSTM. Por ejemplo, una serie temporal univariante se representa como un vector de observaciones:\n",
    "$$\n",
    "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "$$\n",
    "\n",
    "Recuerde que todos los alogoritmos de aprendizaje supervizado necesitan que la información se suministre de la siguiente forma:\n",
    "\n",
    "|       X,       |       y       |\n",
    "|:--------------:|:-------------:|\n",
    "| sample input,  | sample output |\n",
    "| sample input,  | sample output |\n",
    "| sample input,  | sample output |\n",
    "|       ...      |               |\n",
    "\n",
    "Una serie temporal debe transformarse en muestras con componentes de entrada y salida. **La transformación informa tanto de lo que aprenderá el modelo como de cómo se pretende utilizar el modelo en el futuro a la hora de hacer predicciones**. Por ejemplo, lo que se necesita para hacer una predicción (X) y la predicción que se realiza (y). Para un problema de series temporales univariantes en el que nos interesan las predicciones de un paso, se utilizan como entrada las observaciones de los pasos temporales anteriores, denominadas observaciones retardadas, y la **salida es la observación del paso temporal actual**. Por ejemplo, la serie univariante de 10 pasos anterior puede expresarse como un problema de aprendizaje supervisado <font color=red> con tres pasos temporales como entrada</font> y <font color=blue> un paso como salida </font>, de la siguiente manera:\n",
    "\n",
    "|     X,     |  y  |\n",
    "|:----------:|:---:|\n",
    "| [1, 2, 3], | [4] |\n",
    "| [2, 3, 4], | [5] |\n",
    "| [3, 4, 5], | [6] |\n",
    "|     ...    |     |\n",
    "\n",
    "Creemos una función que a partir de una secuencia de valores cree las muestras $X$ y $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c2201d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir la siguiente serie de tiempo a su representación en tensores y explicar \n",
    "# el porque de esa representación\n",
    "# [1,2,3,4,5,6,7,8,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e51d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[[[1 6], [2 7], [3 8]],\n",
    "# [2, 3, 4],\n",
    "# [3, 4, 5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83d6205a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1, 2, 3],\n",
       "        [2, 3, 4],\n",
       "        [3, 4, 5],\n",
       "        [4, 5, 6],\n",
       "        [5, 6, 7],\n",
       "        [6, 7, 8]]),\n",
       " [4, 5, 6, 7, 8, 9],\n",
       " (6, 3))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "timeseries = [i for i in range(1, 10)]\n",
    "\n",
    "size = 3\n",
    "X = []\n",
    "y = []\n",
    "for i in range(len(timeseries)):\n",
    "    if i + size >= len(timeseries):\n",
    "        break\n",
    "    X.append(timeseries[i:i + size])\n",
    "    y.append(timeseries[i + size])\n",
    "\n",
    "X = np.array(X)\n",
    "X, y, X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f534ac92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "883027d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividir una secuencia univariada en muestras\n",
    "def split_sequence(sequence, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        # encontrar el final de este patrón\n",
    "        end_ix = i + n_steps\n",
    "        \n",
    "        # comprobar si estamos más allá de la secuencia\n",
    "        if end_ix > len(sequence)-1:\n",
    "            break\n",
    "        # reunir partes de entrada y salida del patrón\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de739ce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(522)\n",
    "\n",
    "data = np.arange(1, 11)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b260d85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X\n",
      "[[1 2 3]\n",
      " [2 3 4]\n",
      " [3 4 5]\n",
      " [4 5 6]\n",
      " [5 6 7]\n",
      " [6 7 8]\n",
      " [7 8 9]]\n",
      "y\n",
      "[ 4  5  6  7  8  9 10]\n"
     ]
    }
   ],
   "source": [
    "X, y = split_sequence(data, 3)\n",
    "print('X', X, 'y', y, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af53120",
   "metadata": {},
   "source": [
    "Cada columna representará una característica del modelo y podrá corresponder a una observación de retardo distinta. Cada fila representará una muestra y corresponderá a un nuevo ejemplo con componentes de entrada y salida.\n",
    "- **Característica**: Una columna de un conjunto de datos, como una observación de retardo de un conjunto de datos de series temporales.\n",
    "- **Muestra**: Una fila de un conjunto de datos, como una secuencia de entrada y salida de un conjunto de datos de series temporales.\n",
    "\n",
    "| x1, | x2, | x3, | y |\n",
    "|-----|-----|-----|---|\n",
    "|  1, |  2, | 3,  | 4 |\n",
    "|  2, |  3, | 4,  | 5 |\n",
    "|  3, |  4, | 5,  | 6 |\n",
    "| ... |     |     |   |\n",
    "\n",
    "Los datos en esta forma pueden utilizarse directamente para entrenar una red neuronal simple, como un Perceptrón Multicapa. Los datos con la transformación dada estarán distribuidos como **muestras x características**.\n",
    "\n",
    "## 2. Aspectos básicos de la preparación de datos 3D\n",
    "\n",
    "Preparar datos de series temporales para CNNs y LSTMs requiere un paso adicional más allá de transformar los datos en un problema de aprendizaje supervisado. La capa de entrada de los modelos CNN y LSTM se especifica mediante el argumento `input_shape` en la primera capa oculta de la red.\n",
    "\n",
    "La capa LSTM() y CNN() deben especificar la forma de los datos de entrada. **La entrada de cada capa CNN y LSTM debe ser tridimensional**. Las tres dimensiones de esta entrada son:  \n",
    "- **Muestras**. Una secuencia es una muestra. Un lote se compone de una o más muestras.\n",
    "- **Pasos de tiempo**. Un paso de tiempo es un punto de observación en la muestra. Una muestra se compone de varios pasos temporales.\n",
    "- **Características**. Una característica es una observación en un paso de tiempo. Un paso de tiempo se compone de una o más características.\n",
    "\n",
    "Esta estructura tridimensional esperada de los datos de entrada se resume a menudo utilizando la notación de forma de matriz de: `[muestras, pasos de tiempo, características]`. Recuerde que la forma bidimensional de un conjunto de datos con la que estamos familiarizados de la sección anterior tiene la forma de matriz de` [muestras, características]`. Esto significa que estamos añadiendo la nueva dimensión de pasos temporales. Excepto que, en los problemas de predicción de series temporales, nuestras características son observaciones en pasos temporales. Así que, <font color=red> **en realidad, estamos añadiendo la dimensión de las características, donde una serie temporal univariante sólo tiene una característica**. </font>\n",
    "\n",
    "Cuando empecemos a implementar redes `LSTM` en tensorflow, hay que tener en cuenta que la primera capa de este tipo de redes define inicialmente el tamaño de la `capa oculta` y no la capa de entrada. Por ejemplo, si definimos lo siguiente red sin capa de entrada,\n",
    "```\n",
    "# Red sin capa de entrada\n",
    "...\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, input_shape=(3, 1))\n",
    "model.add(Dense(1))\n",
    "```\n",
    "Esta es una red que espera 1 o más `muestras`, 3 `pasos de tiempo`, 1 `característica` y 32 se refiere al `número de unidades en la primera capa oculta`. El número de unidades de la primera capa no tiene nada que ver con el número de muestras, pasos temporales o características de los datos de entrada.\n",
    "\n",
    "En nuestro ejemplo anterior, debemos de convertir nuestros datos una dimensión adicional para que podamos tener nuestros datos tridimensionales. Recordemos que nuestros datos tienen la siguiente caraterística: tenemos 7 `muestras`y 3 `pasos de tiempo por muestra` y como contamos con una serie temporal univariada contamos con 1 `característica`. Por lo que nuestros datos deben de tener la forma de `(7, 3, 1)`, el cuál lo podemos hacer con el comando de numpy `reshape()`. Observemos el ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "335c8bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 3, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convertir la siguiente serie de tiempo a su representación en tensores y explicar \n",
    "# el porque de esa representación\n",
    "# [1,2,3,4,5,6,7,8,9]\n",
    "\n",
    "X.reshape(X.shape[0], X.shape[1], 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32b546f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [2, 3, 4],\n",
       "       [3, 4, 5],\n",
       "       [4, 5, 6],\n",
       "       [5, 6, 7],\n",
       "       [6, 7, 8],\n",
       "       [7, 8, 9]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5902c3de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1],\n",
       "        [2],\n",
       "        [3]],\n",
       "\n",
       "       [[2],\n",
       "        [3],\n",
       "        [4]],\n",
       "\n",
       "       [[3],\n",
       "        [4],\n",
       "        [5]],\n",
       "\n",
       "       [[4],\n",
       "        [5],\n",
       "        [6]],\n",
       "\n",
       "       [[5],\n",
       "        [6],\n",
       "        [7]],\n",
       "\n",
       "       [[6],\n",
       "        [7],\n",
       "        [8]],\n",
       "\n",
       "       [[7],\n",
       "        [8],\n",
       "        [9]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tran = X.reshape((7, 3, 1))\n",
    "X_tran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be999a03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1],\n",
       "        [2],\n",
       "        [3]],\n",
       "\n",
       "       [[2],\n",
       "        [3],\n",
       "        [4]],\n",
       "\n",
       "       [[3],\n",
       "        [4],\n",
       "        [5]],\n",
       "\n",
       "       [[4],\n",
       "        [5],\n",
       "        [6]],\n",
       "\n",
       "       [[5],\n",
       "        [6],\n",
       "        [7]],\n",
       "\n",
       "       [[6],\n",
       "        [7],\n",
       "        [8]],\n",
       "\n",
       "       [[7],\n",
       "        [8],\n",
       "        [9]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# De forma genérica transformaríamos una matriz 2D a 3D usando lo siguiente \n",
    "# Matriz.reshape(#Filas, #Columnas, #Número de entradas)\n",
    "X_tran = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "X_tran"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdd5169",
   "metadata": {},
   "source": [
    "# Ejemplo de preparación de datos\n",
    "Para nuestro ejemplo vamos a seguir los siguientes pasos:\n",
    "1. Cargar los datos.\n",
    "2. Quitar la columna de tiempo.\n",
    "3. Particionar los datos en muestras.\n",
    "4. Reacomodar secuencias en datos tridimensionales (tensores)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5002cade",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(10, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08f084bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    1,    10],\n",
       "       [    2,    20],\n",
       "       [    3,    30],\n",
       "       ...,\n",
       "       [ 4998, 49980],\n",
       "       [ 4999, 49990],\n",
       "       [ 5000, 50000]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Vamos a generar unos datos ficticios\n",
    "\n",
    "# Cantidad de muestras\n",
    "n = 5000\n",
    "timeseries = []\n",
    "for i in range(n):\n",
    "    timeseries.append([i + 1, (i + 1) * 10])\\\n",
    "\n",
    "timeseries = np.array(timeseries)\n",
    "timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "759e07c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   10,    20,    30, ..., 49980, 49990, 50000])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Quitar la columna de tiempo\n",
    "data = timeseries[:, 1]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b7cbe065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.36 µs ± 232 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# 3.1 Paticionar los datos LSTM trabaja mejor con 200-400 pasos de tiempo\n",
    "size_batch = 200\n",
    "\n",
    "data_batch = [data[i:i + size_batch] for i in range(0, len(data), size_batch)]\n",
    "data_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7f039920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2e69d40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.4 µs ± 2.37 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# 3.2 El mismo resultado usando numpy (np.split)\n",
    "data_batch_np = np.split(data, data.shape[0]/size_batch)\n",
    "data_batch_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f41b440e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_batch_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f0490ae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   10,    20,    30, ...,  1980,  1990,  2000],\n",
       "       [ 2010,  2020,  2030, ...,  3980,  3990,  4000],\n",
       "       [ 4010,  4020,  4030, ...,  5980,  5990,  6000],\n",
       "       ...,\n",
       "       [44010, 44020, 44030, ..., 45980, 45990, 46000],\n",
       "       [46010, 46020, 46030, ..., 47980, 47990, 48000],\n",
       "       [48010, 48020, 48030, ..., 49980, 49990, 50000]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Reacomodar las secuencias\n",
    "X = np.array(data_batch)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f0274c8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 200)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3119330e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[   10],\n",
       "        [   20],\n",
       "        [   30],\n",
       "        ...,\n",
       "        [ 1980],\n",
       "        [ 1990],\n",
       "        [ 2000]],\n",
       "\n",
       "       [[ 2010],\n",
       "        [ 2020],\n",
       "        [ 2030],\n",
       "        ...,\n",
       "        [ 3980],\n",
       "        [ 3990],\n",
       "        [ 4000]],\n",
       "\n",
       "       [[ 4010],\n",
       "        [ 4020],\n",
       "        [ 4030],\n",
       "        ...,\n",
       "        [ 5980],\n",
       "        [ 5990],\n",
       "        [ 6000]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[44010],\n",
       "        [44020],\n",
       "        [44030],\n",
       "        ...,\n",
       "        [45980],\n",
       "        [45990],\n",
       "        [46000]],\n",
       "\n",
       "       [[46010],\n",
       "        [46020],\n",
       "        [46030],\n",
       "        ...,\n",
       "        [47980],\n",
       "        [47990],\n",
       "        [48000]],\n",
       "\n",
       "       [[48010],\n",
       "        [48020],\n",
       "        [48030],\n",
       "        ...,\n",
       "        [49980],\n",
       "        [49990],\n",
       "        [50000]]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. Convertir a su representación tensorial \n",
    "X_ten = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "X_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1ee5f135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 200, 1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tamaño del tensor final\n",
    "X_ten.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
