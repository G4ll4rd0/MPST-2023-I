{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02448389",
   "metadata": {},
   "source": [
    "___\n",
    "<img style=\"float: right; margin: 0px 0px 15px 15px;\" src=\"https://www.researchgate.net/publication/331474581/figure/fig1/AS:1131188974567432@1646707876257/A-unified-deep-learning-framework-for-time-series-classification.png\" width=\"500px\" height=\"300px\" />\n",
    "\n",
    "\n",
    "# <font color= #8A0829> Clasificación de series de tiempo usando algoritmos de ML.</font>\n",
    "\n",
    "<Strong> Objetivos </Strong>\n",
    "- Cómo cargar y evaluar algoritmos de aprendizaje automático no lineales y de conjunto en la versión con ingeniería de características del conjunto de datos de reconocimiento de actividad.\n",
    "- Cómo cargar y evaluar algoritmos de aprendizaje automático en los datos de señal sin procesar del conjunto de datos de reconocimiento de actividades.\n",
    "\n",
    "> Referencias:\n",
    "    > - Capítulo 23 de [Deep Learning for Time Series Forecasting: Predict the Future with MLPs, CNNs and LSTMs in Python](https://machinelearningmastery.com/deep-learning-for-time-series-forecasting/)\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0354c4",
   "metadata": {},
   "source": [
    "# 1. Modelado de datos de ingeniería de características\n",
    "\n",
    "En esta sección, desarrollaremos el código para cargar la versión del conjunto de datos con ingeniería de características y evaluaremos un conjunto de algoritmos de aprendizaje automático no lineal, incluido el SVM utilizado en el artículo original. **El objetivo es lograr al menos un 89% de precisión en el conjunto de datos de prueba**. Los resultados de los métodos que utilizan la versión con características modificadas del conjunto de datos proporcionan una línea de base para cualquier método desarrollado para la versión de datos sin procesar desarrollado en sesiones previas.\n",
    "\n",
    "## 1.0 Selección de características \n",
    "\n",
    "\n",
    "Las características seleccionadas para esta base de datos proceden de las señales brutas triaxiales del acelerómetro y el giroscopio tAcc-XYZ y tGyro-XYZ. Estas señales en el dominio del tiempo (prefijo \"t\" para denotar el tiempo) se capturaron a una frecuencia constante de 50 Hz. A continuación, se filtraron utilizando un filtro de mediana y un filtro Butterworth de paso bajo de 3er orden con una frecuencia de esquina de 20 Hz para eliminar el ruido. Del mismo modo, la señal de aceleración se separó en señales de aceleración del cuerpo y de la gravedad (tBodyAcc-XYZ y tGravityAcc-XYZ) utilizando otro filtro Butterworth de paso bajo con una frecuencia de esquina de 0,3 Hz. \n",
    "\n",
    "Posteriormente, la aceleración lineal del cuerpo y la velocidad angular se derivaron en el tiempo para obtener las señales Jerk (tBodyAccJerk-XYZ y tBodyGyroJerk-XYZ). También se calculó la magnitud de estas señales tridimensionales utilizando la norma euclidiana (tBodyAccMag, tGravityAccMag, tBodyAccJerkMag, tBodyGyroMag, tBodyGyroJerkMag). \n",
    "\n",
    "Por último, se aplicó una transformada rápida de Fourier (FFT) a algunas de estas señales para obtener fBodyAcc-XYZ, fBodyAccJerk-XYZ, fBodyGyro-XYZ, fBodyAccJerkMag, fBodyGyroMag, fBodyGyroJerkMag. (Nótese la \"f\" para indicar las señales en el dominio de la frecuencia). \n",
    "\n",
    "Estas señales se utilizaron para estimar las variables del vector de características de cada patrón:  \n",
    "-XYZ' se utiliza para denotar señales de 3 ejes en las direcciones X, Y y Z.\n",
    "\n",
    "        tBodyAcc-XYZ\n",
    "        tGravityAcc-XYZ\n",
    "        tBodyAccJerk-XYZ\n",
    "        tBodyGyro-XYZ\n",
    "        tBodyGyroJerk-XYZ\n",
    "        tBodyAccMag\n",
    "        tGravityAccMag\n",
    "        tBodyAccJerkMag\n",
    "        tBodyGyroMag\n",
    "        tBodyGyroJerkMag\n",
    "        fBodyAcc-XYZ\n",
    "        fBodyAccJerk-XYZ\n",
    "        fBodyGyro-XYZ\n",
    "        fBodyAccMag\n",
    "        fBodyAccJerkMag\n",
    "        fBodyGyroMag\n",
    "        fBodyGyroJerkMag\n",
    "\n",
    "El conjunto de variables que se estimaron a partir de estas señales son: \n",
    "\n",
    "        mean(): Valor medio\n",
    "        std(): Desviación estándar\n",
    "        mad(): Desviación absoluta mediana \n",
    "        max(): Mayor valor de la matriz\n",
    "        min(): Valor más pequeño de la matriz\n",
    "        sma(): Área de magnitud de la señal\n",
    "        energía(): Medida de energía. Suma de los cuadrados dividida por el número de valores. \n",
    "        iqr(): Rango intercuartílico \n",
    "        entropía(): Entropía de la señal\n",
    "        arCoeff(): Coeficientes de autorregresión con orden Burg igual a 4\n",
    "        correlation(): Coeficiente de correlación entre dos señales\n",
    "        maxInds(): índice de la componente de frecuencia de mayor magnitud\n",
    "        mediaFreq(): Media ponderada de las componentes de frecuencia para obtener una frecuencia media\n",
    "        skewness(): asimetría de la señal en el dominio de la frecuencia \n",
    "        curtosis(): curtosis de la señal en el dominio de la frecuencia \n",
    "        bandasEnergía(): Energía de un intervalo de frecuencia dentro de los 64 bins de la FFT de cada ventana.\n",
    "        ángulo(): Ángulo entre to vectores.\n",
    "\n",
    "Vectores adicionales obtenidos promediando las señales en una muestra de ventana de señal. Se utilizan en la variable angle():\n",
    "\n",
    "        gravityMean\n",
    "        tBodyAccMean\n",
    "        tBodyAccJerkMean\n",
    "        tBodyGyroMean\n",
    "        tBodyGyroJerkMean\n",
    "\n",
    "La lista completa de variables de cada vector de características está disponible en 'features.txt'\n",
    "\n",
    "## 1.1 Carga de datos\n",
    "\n",
    "En esta ocasión cargaremos los datos que cuentan con la información de los datos con la ingeniería de características que cuentan con los datos de entrada $X$ y salida $y$. Para ello vamos a cargar los siguientes archivos\n",
    "\n",
    "- UCI HAR Dataset/train/X_train.txt\n",
    "- UCI HAR Dataset/train/y_train.txt\n",
    "- UCI HAR Dataset/test/X_test.txt\n",
    "- UCI HAR Dataset/test/y_test.txt\n",
    "\n",
    "Para este proposito creamos las siguientes funciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97fe30c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de librerías a utilizar\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89b00a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargar un solo archivo como una matriz numpy\n",
    "def load_file(filepath):\n",
    "    dataframe = pd.read_csv(filepath, header=None, delim_whitespace=True)\n",
    "    return dataframe.values\n",
    "\n",
    "\n",
    "# cargar un grupo de conjuntos de datos, como train o test\n",
    "def load_dataset_group(group, prefix=''):\n",
    "    # load input data\n",
    "    X = load_file(prefix + group + '/X_'+group+'.txt')\n",
    "    # load class output\n",
    "    y = load_file(prefix + group + '/y_'+group+'.txt')\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# carga el conjunto de datos, devuelve el los datos de entrenamiento y prueba X y y\n",
    "def load_dataset(prefix=''):\n",
    "    # load all train\n",
    "    trainX, trainy = load_dataset_group('train', prefix + 'UCI HAR Dataset/')\n",
    "    print(trainX.shape, trainy.shape)\n",
    "    # load all test\n",
    "    testX, testy = load_dataset_group('test', prefix + 'UCI HAR Dataset/')\n",
    "    print(testX.shape, testy.shape)\n",
    "    # flatten y\n",
    "    trainy, testy = trainy[:,0], testy[:,0]\n",
    "    print(trainX.shape, trainy.shape, testX.shape, testy.shape)\n",
    "    return trainX, trainy, testX, testy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f8f0f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 561) (7352, 1)\n",
      "(2947, 561) (2947, 1)\n",
      "(7352, 561) (7352,) (2947, 561) (2947,)\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "trainX, trainy, testX, testy = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e618f490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(trainy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cce9d9",
   "metadata": {},
   "source": [
    "## 1.2 Difinición de modelos\n",
    "\n",
    "A continuación, podemos definir una lista de modelos de aprendizaje automático para evaluarlos en este problema. Evaluaremos los modelos utilizando configuraciones predeterminadas. En este punto, no buscamos configuraciones óptimas de estos modelos, sino una idea general del rendimiento de los modelos sofisticados con configuraciones predeterminadas en este problema. Evaluaremos un conjunto diverso de algoritmos de aprendizaje automático no lineales y por grupos, en concreto.\n",
    "\n",
    "Los algoritmos que utlizaremos serán los siguientes:\n",
    "\n",
    "**Nonlinear Algorithms:**\n",
    "- k-Nearest Neighbors\n",
    "- Classification and Regression Tree\n",
    "- Support Vector Machine\n",
    "- Naive Bayes\n",
    "\n",
    "**Ensemble Algorithms:**\n",
    "- Bagged Decision Trees\n",
    "- Random Forest\n",
    "- Extra Trees\n",
    "- Gradient Boosting Machine\n",
    "\n",
    "Para ellos vamos importar los paquetes con los modelos correspondientes y crearemos una función que instancie cada uno de los modelos dentro de un diccionario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "703dcd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar modelos a utilizar\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02e823eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crear un dict de modelos estándar para evaluar {nombre:objeto}\n",
    "def define_models(models=dict()):\n",
    "    # nonlinear models\n",
    "    models['knn'] = KNeighborsClassifier(n_neighbors=7)\n",
    "    models['cart'] = DecisionTreeClassifier()\n",
    "    models['svm'] = SVC()\n",
    "    models['bayes'] = GaussianNB()\n",
    "    \n",
    "    # ensemble models\n",
    "    models['bag'] = BaggingClassifier(n_estimators=100)\n",
    "    models['rf'] = RandomForestClassifier(n_estimators=100)\n",
    "    models['et'] = ExtraTreesClassifier(n_estimators=100)\n",
    "    models['gbm'] = GradientBoostingClassifier(n_estimators=100)\n",
    "    print('Defined %d models' % len(models))\n",
    "    return models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19291a5",
   "metadata": {},
   "source": [
    "## 1.3 Evaluación de modelos\n",
    "\n",
    "Ahora procedemos a crear una función que se encargue de entrenar y evaluar cada algoritmo de clasificación previamente definido en el los datos de entrenamiento y prueba respectivamente. Para este caso usaremos la métrica de `accuracy` para determinar el performance (error) cometido por cada modelo. Como tenemos un diccionario de modelos, generaremos una función que se encargue de iterar sobre cada uno de los modelos y de ejecutar otra función de evaluación. Las funciones serán las siguientes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "670c72c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluar un solo modelo\n",
    "def evaluate_model(trainX, trainy, testX, testy, model):\n",
    "    # Ajustar el modelo\n",
    "    model.fit(trainX, trainy)\n",
    "    # Realizar predicciones\n",
    "    yhat = model.predict(testX)\n",
    "    # Evaluar predicciones\n",
    "    accuracy = accuracy_score(testy, yhat)\n",
    "    return accuracy * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8df4aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar diccionario de modelos {name:object}, regresa {name:score}\n",
    "def evaluate_models(trainX, trainy, testX, testy, models):\n",
    "    results = dict()\n",
    "    for name, model in models.items():\n",
    "        # Evaluar el modelo\n",
    "        results[name] = evaluate_model(trainX, trainy, testX, testy, model)\n",
    "        # Mostrar el proceso\n",
    "        print('>%s: %.3f' % (name, results[name]))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83b54ab",
   "metadata": {},
   "source": [
    "## 1.4 Resumen de resultados\n",
    "\n",
    "Ahora crearemos una función que se encargue de resumir y mostrar todos los resultados obtenidos por cada uno de los modelos ya entrenados. La función será la siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bf602d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimir y mostrar los resultados\n",
    "def summarize_results(results, maximize=True):\n",
    "    # Crear lista de (name, mean(scores)) tuplas\n",
    "    mean_scores = [(k,v) for k,v in results.items()]\n",
    "    # Ordenar tuplas por score\n",
    "    mean_scores = sorted(mean_scores, key=lambda x: x[1])\n",
    "    # reverse para orden descendiente (ej. para accuracy)\n",
    "    if maximize:\n",
    "        mean_scores = list(reversed(mean_scores))\n",
    "    print()\n",
    "    for name, score in mean_scores:\n",
    "        print('Name=%s, Score=%.3f' % (name, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46f39131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 8 models\n",
      ">knn: 90.329\n",
      ">cart: 85.612\n",
      ">svm: 95.046\n",
      ">bayes: 77.027\n",
      ">bag: 90.159\n",
      ">rf: 92.399\n",
      ">et: 93.926\n",
      ">gbm: 93.926\n",
      "\n",
      "Name=svm, Score=95.046\n",
      "Name=gbm, Score=93.926\n",
      "Name=et, Score=93.926\n",
      "Name=rf, Score=92.399\n",
      "Name=knn, Score=90.329\n",
      "Name=bag, Score=90.159\n",
      "Name=cart, Score=85.612\n",
      "Name=bayes, Score=77.027\n"
     ]
    }
   ],
   "source": [
    "# Generar el diccionario de modelos\n",
    "models = define_models()\n",
    "\n",
    "# Evaluar los modelos\n",
    "results = evaluate_models(trainX, trainy, testX, testy, models)\n",
    "\n",
    "# Resumir los resultados de los modelos\n",
    "summarize_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e81b7e0",
   "metadata": {},
   "source": [
    "De los resultados obtenidos podemos ver que los modelos con la ingeniería de características alcanzaron un performance más allá de lo esperado llegando hasta casi el 95% de precisión.\n",
    "\n",
    "Ahora vamos a probar el rendimientos de estos algoritmos usando la data sin la ingeniería de características.\n",
    "\n",
    "# 2. Modelado de datos sin procesar\n",
    "\n",
    "Recordemos que por defecto los datos que tenemos de total acceleration, body acceleration, and body gyroscope ya se encuentran procesados y en forma tensorial `[samples, timesteps, features]`. Para poder tener estos datos adecuados para nuestros algoritmos de ML necesitamos tenerlos en forma matricial, por lo que procederemos a luego de la lectura de archivos, a transformarlos a su forma matricial usando la función `reshape`. Para este proceso usaremos las funciones que desarrollamos en sesiones previas con unas pequeñas variaciones, como se muestra a continuación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e066bd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear función que lee los datos de un archivo en formato txt y los retorna en un dataframe. Están separados por espacios en blanco\n",
    "def load_file(filename):\n",
    "    df = pd.read_csv(filename, delim_whitespace=True, header=None)\n",
    "    return df.values\n",
    "\n",
    "# Crear función que lee los datos de entrenamiento y de prueba\n",
    "def load_group(filenames, prefix=''):\n",
    "    loaded = [load_file(prefix + f) for f in filenames]\n",
    "\n",
    "    # Apilar los datos en un solo array de 3 dimensiones\n",
    "    loaded = np.dstack(loaded)\n",
    "    return loaded\n",
    "\n",
    "# Crear función que lee los datos de entrenamiento y de prueba\n",
    "def load_dataset_group(group, prefix=''):\n",
    "    filepath = prefix + group + '/Inertial Signals/'\n",
    "    # cargar los 9 archivos como un único array\n",
    "    filenames = list()\n",
    "    # total acceleration\n",
    "    filenames += ['total_acc_x_' + group + '.txt', 'total_acc_y_' + group + '.txt',\n",
    "                  'total_acc_z_' + group + '.txt']\n",
    "    # body acceleration\n",
    "    filenames += ['body_acc_x_' + group + '.txt', 'body_acc_y_' + group + '.txt',\n",
    "                  'body_acc_z_' + group + '.txt']\n",
    "    # body gyroscope\n",
    "    filenames += ['body_gyro_x_' + group + '.txt', 'body_gyro_y_' + group + '.txt',\n",
    "                  'body_gyro_z_' + group + '.txt']\n",
    "    # cargar input data\n",
    "    X = load_group(filenames, filepath)\n",
    "    # cargar class output\n",
    "    y = load_file(prefix + group + '/y_' + group + '.txt')\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8be324f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset, returns train and test X and y elements\n",
    "def load_dataset(prefix=''):\n",
    "    # Cargo los datos de entrenamiento\n",
    "    trainX, trainy = load_dataset_group('train', prefix)\n",
    "    print('datos de entrenamiento', trainX.shape, trainy.shape, sep='\\n')\n",
    "    # Cargo los datos de prueba\n",
    "    testX, testy = load_dataset_group('test', prefix)\n",
    "    print('datos de prueba',testX.shape, testy.shape, sep='\\n')\n",
    "    \n",
    "    # flatten X\n",
    "    trainX = trainX.reshape((trainX.shape[0], trainX.shape[1] * trainX.shape[2]))\n",
    "    testX = testX.reshape((testX.shape[0], testX.shape[1] * testX.shape[2]))\n",
    "    \n",
    "    # flatten y\n",
    "    trainy, testy = trainy[:,0], testy[:,0]\n",
    "    print(trainX.shape, trainy.shape, testX.shape, testy.shape)\n",
    "    return trainX, trainy, testX, testy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "377b6164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datos de entrenamiento\n",
      "(7352, 128, 9)\n",
      "(7352, 1)\n",
      "datos de prueba\n",
      "(2947, 128, 9)\n",
      "(2947, 1)\n",
      "(7352, 1152) (7352,) (2947, 1152) (2947,)\n"
     ]
    }
   ],
   "source": [
    "# Cargar los datos de entrenamiento y de prueba\n",
    "trainX, trainy, testX, testy = load_dataset('UCI HAR Dataset/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6f01b8",
   "metadata": {},
   "source": [
    "Con estos datos sin ingeniería de características procedemos a probar su performance en esta nueva data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58edbcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 8 models\n",
      ">knn: 61.893\n",
      ">cart: 72.718\n",
      ">svm: 88.734\n",
      ">bayes: 72.480\n",
      ">bag: 84.459\n",
      ">rf: 84.391\n",
      ">et: 87.139\n"
     ]
    }
   ],
   "source": [
    "# Generar el diccionario de modelos\n",
    "models = define_models()\n",
    "\n",
    "# Evaluar los modelos\n",
    "results = evaluate_models(trainX, trainy, testX, testy, models)\n",
    "\n",
    "# Resumir los resultados de los modelos\n",
    "summarize_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6528ab4",
   "metadata": {},
   "source": [
    "# Extensiones\n",
    "\n",
    "Además de los modelos de ML vistos en esta sesión, hay variaciones que pueden explorarse que pueden mejorar nuestros modelos.\n",
    "\n",
    "- **Más algoritmos**. Sólo se evaluaron ocho algoritmos de aprendizaje automático en el problema; pruebe con algunos métodos lineales y quizá con otros no lineales y de conjunto y analice sus resultados.\n",
    "- **Ajuste de algoritmos**. No se realizó ningún ajuste de los algoritmos de aprendizaje automático; se utilizaron principalmente configuraciones predeterminadas. Elija un método como SVM, ExtraTrees o Gradient Boosting y encuentre el conjunto de hiperparámetros óptimo para ver si puede mejorar aún más el rendimiento en el problema.\n",
    "- **Escalado de datos**. Los datos ya están escalados a [-1,1], quizás por sujeto. Explore si un escalado adicional, como la estandarización, puede resultar en un mejor rendimiento, quizás en métodos sensibles a dicho escalado como kNN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16599b9",
   "metadata": {},
   "source": [
    "<script>\n",
    "  $(document).ready(function(){\n",
    "    $('div.prompt').hide();\n",
    "    $('div.back-to-top').hide();\n",
    "    $('nav#menubar').hide();\n",
    "    $('.breadcrumb').hide();\n",
    "    $('.hidden-print').hide();\n",
    "  });\n",
    "</script>\n",
    "\n",
    "<footer id=\"attribution\" style=\"float:right; color:#808080; background:#fff;\">\n",
    "Created with Jupyter by Oscar David Jaramillo Zuluaga.\n",
    "</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
